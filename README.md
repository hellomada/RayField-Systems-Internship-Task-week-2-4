# Rayfield Systems Week 2: Data Pipeline Design

This repository contains the complete Week 2 deliverables for the Rayfield Systems internship technical track.

## Contents

- `notebooks/` — Jupyter notebooks for data import, cleaning, and exploration  
- `data/` — Raw and cleaned datasets  
- `docs/` — Documentation files including dataset justification, feature plans, AI/ML ideas, and pipeline notes  
- `diagrams/` — Visual pipeline and system flow diagrams

## Overview

This project builds a working prototype data pipeline that loads real wind energy data, cleans and processes it, and prepares features for AI/ML models. The pipeline includes planning for forecasting and anomaly detection, system logic for automation, and documentation of edge cases.

## How to Run

1. Open the notebooks in `notebooks/`  
2. Upload the raw dataset found in `data/raw_data.csv`  
3. Run cells sequentially to clean, explore, and process data  
4. View diagrams in `diagrams/` for pipeline structure  
5. See documentation in `docs/` for detailed plans and explanations
